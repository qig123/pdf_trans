# 8.9 Exercises

404 Chapter 8 Composite Types

considered too expensive for production-quality imperative languages, garbage collection is now standard not only in functional and scripting languages, but in Ada, Java, C#, Scala, and Go, among others. 8.9 Exercises

8.1 Suppose we are compiling for a machine with 1-byte characters, 2-byte shorts, 4-byte integers, and 8-byte reals, and with alignment rules that re- quire the address of every primitive data element to be an even multiple of the element’s size. Suppose further that the compiler is not permitted to reorder ﬁelds. How much space will be consumed by the following array? Explain.

A : array [0..9] of record s : short c : char t : short d : char r : real i : integer

8.2 In Example 8.10 we suggested the possibility of sorting record ﬁelds by their alignment requirement, to minimize holes. In the example, we sorted smallest-alignment-ﬁrst. What would happen if we sorted longest- alignment-ﬁrst? Do you see any advantages to this scheme? Any disad- vantages? If the record as a whole must be an even multiple of the longest alignment, do the two approaches ever differ in total space required? 8.3 Give Ada code to map from lowercase to uppercase letters, using (a) an array (b) a function

Note the similarity of syntax: in both cases upper(‚a‚) is ‚A‚. 8.4 In Section 8.2.2 we noted that in a language with dynamic arrays and a value model of variables, records could have ﬁelds whose size is not known at compile time. To accommodate these, we suggested using a dope vector for the record, to track the offsets of the ﬁelds. Suppose instead that we want to maintain a static offset for each ﬁeld. Can we devise an alternative strategy inspired by the stack frame layout of Figure 8.7, and divide each record into a ﬁxed-size part and a variable-size part? What problems would we need to address? (Hint: Consider nested records.) 8.5 Explain how to extend Figure 8.7 to accommodate subroutine arguments that are passed by value, but whose shape is not known until the subroutine is called at run time.

8.9 Exercises 405

8.6 Explain how to obtain the effect of Fortran 90’s allocate statement for one-dimensional arrays using pointers in C. You will probably ﬁnd that your solution does not generalize to multidimensional arrays. Why not? If you are familiar with C++, show how to use its class facilities to solve the problem. 8.7 Example 8.24, which considered the layout of a two-dimensional array of characters, counted only the space devoted to characters and pointers. This is appropriate if the space is allocated statically, as a global array of days or keywords known at compile time. Supposed instead that space is allocated in the heap, with 4 or 8 bytes of overhead for each contiguous block of storage. How does this change the tradeoffs in space efﬁciency? 8.8 Consider the array indexing calculation of Example 8.25. Suppose that i, j, and k are already loaded into registers, and that A’s elements are inte- gers, allocated contiguously in memory on a 32-bit machine. Show, in the pseudo-assembly notation of Sidebar 5.1, the instruction sequence to load A[i, j, k] into a register. You may assume the existence of an indexed ad- dressing mode capable of scaling by small powers of two. Assuming the ﬁnal memory load is a cache hit, how many cycles is your code likely to require on a modern processor? 8.9 Continuing the previous exercise, suppose that A has row-pointer layout, and that i, j, and k are again available in registers. Show pseudo-assembler code to load A[i, j, k] into a register. Assuming that all memory loads are cache hits, how many cycles is your code likely to require on a modern pro- cessor? 8.10 Repeat the preceding two exercises, modifying your code to include run- time checking of array subscript bounds. 8.11 In Section 8.2.3 we discussed how to differentiate between the constant and variable portions of an array reference, in order to efﬁciently access the sub- parts of array and record objects. An alternative approach is to generate naive code and count on the compiler’s code improver to ﬁnd the constant portions, group them together, and calculate them at compile time. Discuss the advantages and disadvantages of each approach. 8.12 Consider the following C declaration, compiled on a 64-bit x86 machine:

struct { int n; char c; } A[10][10];

If the address of A[0][0] is 1000 (decimal), what is the address of A[3][7]? 8.13 Suppose we are generating code for an imperative language on a machine with 8-byte ﬂoating-point numbers, 4-byte integers, 1-byte characters, and 4-byte alignment for both integers and ﬂoating-point numbers. Suppose

406 Chapter 8 Composite Types

further that we plan to use contiguous row-major layout for multidimen- sional arrays, that we do not wish to reorder ﬁelds of records or pack either records or arrays, and that we will assume without checking that all array subscripts are in bounds. (a) Consider the following variable declarations:

A : array [1..10, 10..100] of real i : integer x : real

Show the code that our compiler should generate for the following as- signment: x := A[3,i]. Explain how you arrived at your answer. (b) Consider the following more complex declarations:

r : record x : integer y : char A : array [1..10, 10..20] of record z : real B : array [0..71] of char j, k : integer

Assume that these declarations are local to the current subroutine. Note the lower bounds on indices in A; the ﬁrst element is A[1,10]. Describe how r would be laid out in memory. Then show code to load r.A[2,j].B[k] into a register. Be sure to indicate which portions of the address calculation could be performed at compile time. 8.14 Suppose A is a 10×10 array of (4-byte) integers, indexed from [0][0] through [9][9]. Suppose further that the address of A is currently in register r1, the value of integer i is currently in register r2, and the value of integer j is currently in register r3. Give pseudo-assembly language for a code sequence that will load the value of A[i][j] into register r1 (a) assuming that A is implemented using (row-major) contiguous allocation; (b) assuming that A is implemented using row pointers. Each line of your pseudocode should correspond to a single instruction on a typical modern machine. You may use as many registers as you need. You need not preserve the values in r1, r2, and r3. You may assume that i and j are in bounds, and that addresses are 4 bytes long. Which code sequence is likely to be faster? Why? 8.15 Pointers and recursive type deﬁnitions complicate the algorithm for deter- mining structural equivalence of types. Consider, for example, the follow- ing deﬁnitions:

type A = record x : pointer to B y : real

8.9 Exercises 407

type B = record x : pointer to A y : real

The simple deﬁnition of structural equivalence given in Section 7.2.1 (ex- pand the subparts recursively until all you have is a string of built-in types and type constructors; then compare them) does not work: we get an inﬁ- nite expansion (type A = record x : pointer to record x : pointer to record x : pointer to record . . . ). The obvious reinterpretation is to say two types A and B are equivalent if any sequence of ﬁeld selections, array subscripts, pointer dereferences, and other operations that takes one down into the structure of A, and that ends at a built-in type, always encounters the same ﬁeld names, and ends at the same built-in type when used to dive into the structure of B—and vice versa. Under this reinterpretation, A and B above have the same type. Give an algorithm based on this reinterpretation that could be used in a compiler to determine structural equivalence. (Hint: The fastest approach is due to J. Král [Krá73]. It is based on the algorithm used to ﬁnd the smallest deterministic ﬁnite automaton that accepts a given reg- ular language. This algorithm was outlined in Example 2.15; details can be found in any automata theory textbook [e.g., [HMU07]].) 8.16 Explain the meaning of the following C declarations:

double *a[n]; double (*b)[n]; double (*c[n])(); double (*d())[n];

8.17 In Ada 83, pointers (access variables) can point only to objects in the heap. Ada 95 allows a new kind of pointer, the access all type, to point to other objects as well, provided that those objects have been declared to be aliased:

type int_ptr is access all Integer; foo : aliased Integer; ip : int_ptr; ... ip := foo'Access;

The ‚Access attribute is roughly equivalent to C’s “address of” (&) oper- ator. How would you implement access all types and aliased objects? How would your implementation interact with automatic garbage collec- tion (assuming it exists) for objects in the heap? 8.18 As noted in Section 8.5.2, Ada 95 forbids an access all pointer from re- ferring to any object whose lifetime is briefer than that of the pointer’s type. Can this rule be enforced completely at compile time? Why or why not?

408 Chapter 8 Composite Types

8.19 In much of the discussion of pointers in Section 8.5, we assumed implicitly that every pointer into the heap points to the beginning of a dynamically allocated block of storage. In some languages, including Algol 68 and C, pointers may also point to data inside a block in the heap. If you were trying to implement dynamic semantic checks for dangling references or, alterna- tively, automatic garbage collection (precise or conservative), how would your task be complicated by the existence of such “internal pointers”? 8.20 (a) Occasionally one encounters the suggestion that a garbage-collected language should provide a delete operation as an optimization: by explicitly delete-ing objects that will never be used again, the pro- grammer might save the garbage collector the trouble of ﬁnding and re- claiming those objects automatically, thereby improving performance. What do you think of this suggestion? Explain. (b) Alternatively, one might allow the programmer to “tenure” an object, so that it will never be a candidate for reclamation. Is this a good idea? 8.21 In Example 8.52 we noted that functional languages can safely use reference counts since the lack of an assignment statement prevents them from intro- ducing circularity. This isn’t strictly true; constructs like the Lisp letrec can also be used to make cycles, so long as uses of circularly deﬁned names are hidden inside lambda expressions in each deﬁnition:

(define foo (lambda () (letrec ((a (lambda(f) (if f #\A b))) (b (lambda(f) (if f #\B c))) (c (lambda(f) (if f #\C a)))) a)))

Each of the functions a, b, and c contains a reference to the next:

((foo) #t) =⇒#\A (((foo) #f) #t) =⇒#\B ((((foo) #f) #f) #t) =⇒#\C (((((foo) #f) #f) #f) #t) =⇒#\A

How might you address this circularity without giving up on reference counts? 8.22 Here is a skeleton for the standard quicksort algorithm in Haskell:

quicksort [] = [] quicksort (a : l) = quicksort [...] ++ [a] ++ quicksort [...]

The ++ operator denotes list concatenation (similar to @ in ML). The : operator is equivalent to ML’s :: or Lisp’s cons. Show how to express the two elided expressions as list comprehensions.

8.23–8.31 In More Depth.

