# 5.2 Cyclic Control Flow and Dataflow Analysis

![Figure 5.3 Interpreter for...](images/page_99_vector_371.png)
*Figure 5.3 Interpreter for LWhile.*

is also #<void>. The (Begin es body) expression evaluates the subexpressions es for their effects and then evaluates and returns the result from body. The (Void) expression produces the #<void> value. The definition of the type checker for LWhile is shown in figure 5.4. The type checking of the SetBang expression requires the type of the variable and the right- hand side to agree. The result type is Void. For while, the condition must be a Boolean and the result type is Void. For Begin, the result type is the type of its last subexpression. At first glance, the translation of these language features to x86 seems straight- forward because the CIf intermediate language already supports all the ingredients that we need: assignment, goto, conditional branching, and sequencing. However, complications arise, which we discuss in the next section. After that we introduce the changes necessary to the existing passes.

5.2 Cyclic Control Flow and Dataflow Analysis

Up until this point, the programs generated in explicate_control were guaranteed to be acyclic. However, each while loop introduces a cycle. Does that matter? Indeed, it does. Recall that for register allocation, the compiler performs liveness

![Figure 5.4 Type checker...](images/page_100_vector_390.png)
*Figure 5.4 Type checker for the LWhile language.*

analysis to determine which variables can share the same register. To accomplish this, we analyzed the control-flow graph in reverse topological order (section 4.10.1), but topological order is well defined only for acyclic graphs. Let us return to the example of computing the sum of the first five posi- tive integers. Here is the program after instruction selection but before register allocation.

```
(define (main) : Integer
mainstart:
movq $0, sum
movq $5, i
jmp block5
block5:
movq i, tmp3
cmpq tmp3, $0
jl block7
jmp block8
```

```
block7:
addq i, sum
movq $1, tmp4
negq tmp4
addq tmp4, i
jmp block5
block8:
movq $27, %rax
addq sum, %rax
jmp mainconclusion)
```

Recall that liveness analysis works backward, starting at the end of each function. For this example we could start with block8 because we know what is live at the beginning of the conclusion: only rax and rsp. So the live-before set for block8 is {rsp,sum}. Next we might try to analyze block5 or block7, but block5 jumps to block7 and vice versa, so it seems that we are stuck. The way out of this impasse is to realize that we can compute an underap- proximation of each live-before set by starting with empty live-after sets. By underapproximation, we mean that the set contains only variables that are live for some execution of the program, but the set may be missing some variables that are live. Next, the underapproximations for each block can be improved by (1) updating the live-after set for each block using the approximate live-before sets from the other blocks, and (2) performing liveness analysis again on each block. In fact, by iterating this process, the underapproximations eventually become the correct solutions! This approach of iteratively analyzing a control-flow graph is applicable to many static analysis problems and goes by the name dataflow analysis. It was invented by Kildall (1973) in his PhD thesis at the University of Washington. Let us apply this approach to the previously presented example. We use the empty set for the initial live-before set for each block. Let m0 be the following mapping from label names to sets of locations (variables and registers):

mainstart: {}, block5: {}, block7: {}, block8: {}

Using the above live-before approximations, we determine the live-after for each block and then apply liveness analysis to each block. This produces our next approximation m1 of the live-before sets.

mainstart: {}, block5: {i}, block7: {i, sum}, block8: {rsp, sum}

For the second round, the live-after for mainstart is the current live-before for block5, which is {i}. Therefore the liveness analysis for mainstart computes the empty set. The live-after for block5 is the union of the live-before sets for block7 and block8, which is {i, rsp, sum}. So the liveness analysis for block5 computes {i, rsp, sum}. The live-after for block7 is the live-before for block5 (from the previous iteration), which is {i}. So the liveness analysis for block7 remains {i, sum}. Together these yield the following approximation m2 of the live-before sets:

mainstart: {}, block5: {i, rsp, sum}, block7: {i, sum}, block8: {rsp, sum}

In the preceding iteration, only block5 changed, so we can limit our attention to mainstart and block7, the two blocks that jump to block5. As a result, the live- before sets for mainstart and block7 are updated to include rsp, yielding the following approximation m3:

mainstart: {rsp}, block5: {i,rsp,sum}, block7: {i,rsp,sum}, block8: {rsp,sum}

Because block7 changed, we analyze block5 once more, but its live-before set remains {i,rsp,sum}. At this point our approximations have converged, so m3 is the solution. This iteration process is guaranteed to converge to a solution by the Kleene fixed-point theorem, a general theorem about functions on lattices (Kleene 1952). Roughly speaking, a lattice is any collection that comes with a partial ordering ⊑ on its elements, a least element ⊥(pronounced bottom), and a join operator ⊔.3

When two elements are ordered mi ⊑mj, it means that mj contains at least as much information as mi, so we can think of mj as a better-than-or-equal-to approximation in relation to mi. The bottom element ⊥represents the complete lack of information, that is, the worst approximation. The join operator takes two lattice elements and combines their information; that is, it produces the least upper bound of the two. A dataflow analysis typically involves two lattices: one lattice to represent abstract states and another lattice that aggregates the abstract states of all the blocks in the control-flow graph. For liveness analysis, an abstract state is a set of locations. We form the lattice L by taking its elements to be sets of locations, the ordering to be set inclusion (⊆), the bottom to be the empty set, and the join operator to be set union. We form a second lattice M by taking its elements to be mappings from the block labels to sets of locations (elements of L). We order the mappings point-wise, using the ordering of L. So, given any two mappings mi and mj, mi ⊑M mj when mi(ℓ) ⊆mj(ℓ) for every block label ℓin the program. The bottom element of M is the mapping ⊥M that sends every label to the empty set, ⊥M(ℓ) = ∅. We can think of one iteration of liveness analysis applied to the whole program as being a function f on the lattice M. It takes a mapping as input and computes a new mapping. f(mi) = mi+1

Next let us think for a moment about what a final solution ms should look like. If we perform liveness analysis using the solution ms as input, we should get ms again as the output. That is, the solution should be a fixed point of the function f.

f(ms) = ms

Furthermore, the solution should include only locations that are forced to be there by performing liveness analysis on the program, so the solution should be the least fixed point. The Kleene fixed-point theorem states that if a function f is monotone (better inputs produce better outputs), then the least fixed point of f is the least upper bound of the ascending Kleene chain that starts at ⊥and iterates f as follows:

⊥⊑f(⊥) ⊑f(f(⊥)) ⊑· · · ⊑f n(⊥) ⊑· · ·

When a lattice contains only finitely long ascending chains, then every Kleene chain tops out at some fixed point after some number of iterations of f.

⊥⊑f(⊥) ⊑f(f(⊥)) ⊑· · · ⊑f k(⊥) = f k+1(⊥) = ms

* Technically speaking, we will be working with join semilattices.

![Figure 5.5 Generic work...](images/page_103_vector_324.png)
*Figure 5.5 Generic work list algorithm for dataflow analysis.*

The liveness analysis is indeed a monotone function and the lattice M has finitely long ascending chains because there are only a finite number of variables and blocks in the program. Thus we are guaranteed that iteratively applying liveness analysis to all blocks in the program will eventually produce the least fixed point solution. Next let us consider dataflow analysis in general and discuss the generic work list algorithm (figure 5.5). The algorithm has four parameters: the control-flow graph G, a function transfer that applies the analysis to one block, and the bottom and join operators for the lattice of abstract states. The analyze_dataflow function is formulated as a forward dataflow analysis; that is, the inputs to the transfer function come from the predecessor nodes in the control-flow graph. However, live- ness analysis is a backward dataflow analysis, so in that case one must supply the analyze_dataflow function with the transpose of the control-flow graph. The algorithm begins by creating the bottom mapping, represented by a hash table. It then pushes all the nodes in the control-flow graph onto the work list (a queue). The algorithm repeats the while loop as long as there are items in the work list. In each iteration, a node is popped from the work list and processed. The input for the node is computed by taking the join of the abstract states of all the predecessor nodes. The transfer function is then applied to obtain the output abstract state. If the output differs from the previous state for this block, the mapping for this block is updated and its successor nodes are pushed onto the work list.

