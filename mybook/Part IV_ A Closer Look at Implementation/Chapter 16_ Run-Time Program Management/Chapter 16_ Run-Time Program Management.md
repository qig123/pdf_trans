# Chapter 16: Run-Time Program Management

16 Run-Time Program Management

Every nontrivial implementation of a high-level programming language makes extensive use of libraries. Some library routines are very simple: they may copy memory from one place to another, or perform arithmetic functions not directly supported by the hardware. Others are more sophisticated. Heap management routines, for example, maintain signiﬁcant amounts of internal state, as do li- braries for buffered or graphical I/O. In general, we use the term run-time system (or sometimes just runtime, with- out the hyphen) to refer to the set of libraries on which the language implemen- tation depends for correct operation. Some parts of the runtime, like heap man- agement, obtain all the information they need from subroutine arguments, and can easily be replaced with alternative implementations. Others, however, require more extensive knowledge of the compiler or the generated program. In simpler cases, this knowledge is really just a set of conventions (e.g., for the subroutine calling sequence) that the compiler and runtime both respect. In more complex cases, the compiler generates program-speciﬁc metadata that the runtime must inspect to do its job. A tracing garbage collector (Section 8.5.3), for example, de- pends on metadata identifying all the “root pointers” in the program (all global, static, and stack-based pointer or reference variables), together with the type of every reference and of every allocated block. Many examples of compiler/runtime integration have been discussed in previ- ous chapters; we review these in Sidebar 16.1. The length and complexity of the list generally means that the compiler and the run-time system must be developed together. Some languages (notably C) have very small run-time systems: most of the user-level code required to execute a given source program is either generated directly by the compiler or contained in language-independent libraries. Other languages have extensive run-time systems. C#, for example, is heavily dependent on a run-time system deﬁned by the Common Language Infrastructure (CLI) standard [Int12a]. Like any run-time system, the CLI depends on data generated by the com- EXAMPLE 16.1

The CLI as a run-time system and virtual machine piler (e.g., type descriptors, lists of exception handlers, and certain content from the symbol table). It also makes extensive assumptions about the structure of

807

808 Chapter 16 Run-Time Program Management

DESIGN & IMPLEMENTATION

16.1 Run-time systems

Many of the most interesting topics in language implementation revolve around the run-time system, and have been covered in previous chapters. To set the stage for virtual machines, we review those topics here.

Garbage Collection (Section 8.5.3). As noted in the chapter introduction, a tracing garbage collector must be able to ﬁnd all the “root pointers” in the program, and to identify the type of every reference and every allocated block. A compacting collector must be able to modify every pointer in the program. A generational collector must have access to a list of old-to-new pointer ref- erences, maintained by write barriers in the main program. A collector for a language like Java must call appropriate finalize methods. And in imple- mentations that support concurrent or incremental collection, the main pro- gram and the collector must agree on some sort of locking protocol to preserve the consistency of the heap.

Variable Numbers of Arguments (Section 9.3.3). Several languages allow the programmer to declare functions that take an arbitrary number of arguments, of arbitrary type. In C, a call to va_arg(my_args, arg_type) must return the next argument in the previously identiﬁed list my_args. To ﬁnd the argument, va_arg must understand which arguments are passed in which registers, and which arguments are passed on the stack (with what alignment, padding, and offset). If the code for va_arg is generated entirely in-line, this knowledge may be embedded entirely in the compiler. If any of the code is in library routines, however, those routines are compiler-speciﬁc, and thus a (simple) part of the run-time system.

Exception Handling (Section 9.4). Exception propagation requires that we “unwind” the stack whenever control escapes the current subroutine. Code to deallocate the current frame may be generated by the compiler on a subroutine-by-subroutine basis. Alternatively, a general-purpose routine to deallocate any given frame may be part of the run-time system. In a similar vein, the closest exception handler around a given point in the program may be found by compiler-generated code that maintains a stack of active handlers, or by a general-purpose run-time routine that inspects a table of program- counter-to-handler mappings generated at compile time. The latter approach avoids any run-time cost when entering and leaving a protected region (try block).

Event Handling (Section 9.6). Events are commonly implemented as “spon- taneous” subroutine calls in a single-threaded program, or as “callbacks” in a separate, dedicated thread of a concurrent program. Depending on imple- mentation strategy, they may be able to exploit knowledge of the compiler’s

Chapter 16 Run-Time Program Management 809

subroutine calling conventions. They also require synchronization between the main program and the event handler, to protect the consistency of shared data structures. A truly asynchronous call—one that may interrupt execution of the main program at any point—may need to save the entire register set of the machine. Calls that occur only at well-deﬁned “safe points” in the program (implemented via polling) may be able to save a smaller amount of state. In either case, calls to any handler not at the outermost level of lexical nesting may need to interpret a closure to establish the proper referencing environment.

Coroutine and Thread Implementation (Sections 9.5 and 13.2.4). Code to create a coroutine or thread must allocate and initialize a stack, establish a referencing environment, perform any set-up needed to handle future excep- tions, and invoke a speciﬁed start-up routine. Routines like transfer, yield, reschedule, and sleep on (as well as any scheduler-based synchronization mechanisms) must likewise understand a wealth of details about the imple- mentation of concurrency.

Remote Procedure Call (Section C 13.5.4). Remote procedure call (RPC) merges aspects of events and threads: from the server’s point of view, an RPC is an event executed by a separate thread in response to a request from a client. Whether built into the language or implementedvia a stub compiler, it requires a run-time system (dispatcher) with detailed knowledge of calling conventions, concurrency, and storage management.

Transactional Memory (Section 13.4.4). A software implementation of trans- actional memory must buffer speculative updates, track speculative reads, de- tect conﬂicts with other transactions, and validate its view of memory before performing any operation that might be compromised by inconsistency. It must also be prepared to roll back its updates if aborted, or to make them per- manent if committed. These operations typically require library calls at the beginning and end of every transaction, and at most read and write instruc- tions in between. Among other things, these calls must understand the layout of objects in memory, the meaning of metadata associated with objects and transactions, and the policy for arbitrating between conﬂicting transactions.

Dynamic Linking (Section C 15.7). In any system with separate compilation, the compiler generates symbol table information that the linker uses to resolve external references. In a system with fully dynamic (lazy) linking, external ref- erences are (temporarily) ﬁlled with pointers to the linker, which must then be part of the run-time system. When the program tries to call a routine that has not yet been linked, it actually calls the linker, which resolves the refer- ence dynamically. Speciﬁcally, the linker looks up symbol table information describing the routine to be called. It then patches, in a manner consistent with the language’s subroutine calling conventions, the linkage tables that will govern future calls.

