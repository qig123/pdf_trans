# 13.9 Bibliographic Notes

13.9 Bibliographic Notes
**697**

```
particular attention to the retry and orElse mechanisms. Discuss their
similarities to—and advantages over—conditional critical regions.
13.47
Study the documentation for some of your favorite library packages (the C
and C++ standard libraries, perhaps, or the .NET and Java libraries, or the
many available packages for mathematical computing). Which routines
can safely be called from a multithreaded program? Which cannot? What
accounts for the difference? Why not make all routines thread safe?
13.48
Undertake a detailed study of several concurrent languages. Download
implementations and use them to write parallel programs of several dif-
ferent sorts. (You might, for example, try Conway’s Game of Life, Delau-
nay Triangulation, and Gaussian Elimination; descriptions of all of these
can easily be found on the Web.) Write a paper about your experience.
What worked well? What didn’t? Languages you might consider include
Ada, C#, Cilk, Erlang, Go, Haskell, Java, Modula-3, Occam, Rust, SR, and
Swift. References for all of these can be found in Appendix A.
13.49
Learn about the supercomputing languages discussed in the Bibliographic
Notes at the end of the chapter: Co-Array Fortran, Titanium, and UPC;
and Chapel, Fortress, and X10. How do these compare to one another?
To MPI and OpenMP? To languages with less of a focus on “high-end”
computing?
13.50
In the spirit of the previous question, learn about the SHMEM library
package, originally developed by Robert Numrich of Cray, Inc., and now
standardized as OpenSHMEM (openshmem.org). SHMEM is widely used
for parallel programming on both large-scale multiprocessors and clusters.
It has been characterized as a cross between shared memory and message
passing. Is this a fair characterization? Under what circumstances might a
shmem program be expected to outperform solutions in MPI or OpenMP?
13.51
Much of this chapter has been devoted to the management of races in par-
allel programs. The complexity of the task suggests a tantalizing question:
is it possible to design a concurrent programming language that is pow-
erful enough to be widely useful, and in which programs are inherently
race-free? For three very different takes on a (mostly) afﬁrmative answer,
see the work of Edward Lee [Lee06], the various concurrent dialects of
Haskell [NA01, JGF96], and Deterministic Parallel Java (DPJ) [BAD+09].
```

13.52–13.54 In More Depth.
## 13.9

**Bibliographic Notes**
Much of the early study of concurrency stems from a pair of articles by Dijk-
stra [Dij68a, Dij72]. Andrews and Schneider [AS83] provided an excellent snap-
shot of the ﬁeld in the early 1980s. Holt et al. [HGLS78] is a useful reference for
many of the classic problems in concurrency and synchronization.

