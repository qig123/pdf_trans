690
Chapter 13 Concurrency
languages being designed for purely sequential execution. As of 2015, explic-
itly parallel languages have yet to seriously undermine the dominance of MPI for
high-end scientiﬁc computing, though this, too, may change in coming years.
13.7
Exercises
13.1
Give an example of a “benign” race condition—one whose outcome affects
program behavior, but not correctness.
13.2
We have deﬁned the ready list of a thread package to contain all threads
that are runnable but not running, with a separate variable to identify the
currently running thread. Could we just as easily have deﬁned the ready
list to contain all runnable threads, with the understanding that the one at
the head of the list is running? (Hint: Think about multiprocessors.)
13.3
Imagine you are writing the code to manage a hash table that will be shared
among several concurrent threads. Assume that operations on the table
need to be atomic. You could use a single mutual exclusion lock to protect
the entire table, or you could devise a scheme with one lock per hash-
table bucket. Which approach is likely to work better, under what circum-
stances? Why?
13.4
The typical spin lock holds only one bit of data, but requires a full word
of storage, because only full words can be read, modiﬁed, and written
atomically in hardware. Consider, however, the hash table of the previ-
ous exercise. If we choose to employ a separate lock for each bucket of the
table, explain how to implement a “two-level” locking scheme that cou-
ples a conventional spin lock for the table as a whole with a single bit of
locking information for each bucket. Explain why such a scheme might be
desirable, particularly in a table with external chaining.
13.5
Drawing inspiration from Examples 13.29 and 13.30, design a non-
blocking linked-list implementation of a stack using compare_and_swap.
(When CAS was ﬁrst introduced, on the IBM 370 architecture, this algo-
rithm was one of the driving applications [Tre86].)
13.6
Building on the previous exercise, suppose that stack nodes are dynami-
cally allocated. If we read a pointer and then are delayed (e.g., due to pre-
emption), the node to which the pointer refers may be reclaimed and then
reallocated for a different purpose. A subsequent compare-and-swap may
then succeed when logically it should not. This issue is known as the ABA
problem.
Give a concrete example—an interleaving of operations in two or more
threads—where the ABA problem may result in incorrect behavior for
your stack. Explain why this behavior cannot occur in systems with au-
tomatic garbage collection. Suggest what might be done to avoid it in
systems with manual storage management.
13.7 Exercises
691
13.7
We noted in Section 13.3.2 that several processors, including the ARM,
MIPS, and Power, provide an alternative to compare_and_swap (CAS)
known as load_linked/store_conditional (LL/SC). A load_linked
instruction loads a memory location into a register and stores certain
bookkeeping information into hidden processor registers.
A store_
conditional instruction stores the register back into the memory loca-
tion, but only if the location has not been modiﬁed by any other processor
since the load_linked was executed. Like compare_and_swap, store_
conditional returns an indication of whether it succeeded or not.
(a) Rewrite the code sequence of Example 13.29 using LL/SC.
(b) On most machines, an SC instruction can fail for any of several “spu-
rious” reasons, including a page fault, a cache miss, or the occurrence
of an interrupt in the time since the matching LL. What steps must a
programmer take to make sure that algorithms work correctly in the
face of such failures?
(c)
Discuss the relative advantages of LL/SC and CAS. Consider how they
might be implemented on a cache-coherent multiprocessor. Are there
situations in which one would work but the other would not? (Hints:
Consider algorithms in which a thread may need to touch more than
one memory location. Also consider algorithms in which the contents
of a memory location might be changed and then restored, as in the
previous exercise.)
13.8
Starting with the test-and-test_and_set lock of Figure 13.8, implement
busy-wait code that will allow readers to access a data structure concur-
rently. Writers will still need to lock out both readers and other writers.
You may use any reasonable atomic instruction(s) (e.g., LL/SC). Consider
the issue of fairness. In particular, if there are always readers interested in
accessing the data structure, your algorithm should ensure that writers are
not locked out forever.
13.9
Assuming the Java memory model,
(a) Explain why it is not sufﬁcient in Figure 13.11 to label X and Y as
volatile.
(b) Explain why it is sufﬁcient, in that same ﬁgure, to enclose C’s reads
(and similarly those of D) in a synchronized block for some com-
mon shared object O.
(c)
Explain why it is sufﬁcient, in Example 13.31, to label both inspected
and X as volatile, but not to label only one.
(Hint: You may ﬁnd it useful to consult Doug Lea’s Java Memory Model
“Cookbook for Compiler Writers,” at gee.cs.oswego.edu/dl/jmm/cookbook.
html).
13.10
Implement the nonblocking queue of Example 13.30 on an x86. (Com-
plete pseudocode can be found in the paper by Michael and Scott [MS98].)
692
Chapter 13 Concurrency
Do you need fence instructions to ensure consistency? If you have access
to appropriate hardware, port your code to a machine with a more relaxed
memory model (e.g., ARM or Power). What new fences or atomic refer-
ences do you need?
13.11
Consider the implementation of software transactional memory in Fig-
ure 13.19.
(a) How would you implement the read set, write map, and lock map
data structures? You will want to minimize the cost not only of insert
and lookup operations but also of (1) “zeroing out” the table at the
end of a transaction, so it can be used again; and (2) extending the
table if it becomes too full.
(b) The validate routine is called in two different places. Expand these
calls in-line and customize them to the calling context. What opti-
mizations can you achieve?
(c)
Optimize the commit routine to exploit the fact that a ﬁnal validation
is unnecessary if no other transaction has committed since valid time.
(d) Further optimize commit by observing that the for loop in the ﬁnally
clause really needs to iterate over orecs, not over addresses (there may
be a difference, if more than one address hashes to the same orec).
What data, ideally, should lock map hold?
13.12
The code of Example 13.35 could fairly be accused of displaying poor ab-
straction. If we make desired condition a delegate (a subroutine or object
closure), can we pass it as an extra parameter, and move the signal and
scheduler lock management inside sleep on? (Hint: Consider the code
for the P operation in Figure 13.15.)
13.13
The mechanism used in Figure 13.13 to make scheduler code reentrant
employs a single OS-provided lock for all the scheduling data structures
of the application. Among other things, this mechanism prevents threads
on separate processors from performing P or V operations on unrelated
semaphores, even when none of the operations needs to block. Can you
devise another synchronization mechanism for scheduler-related opera-
tions that admits a higher degree of concurrency but that is still correct?
13.14
Show how to implement a lock-based concurrent set as a singly linked
sorted list. Your implementation should support insert, ﬁnd, and remove
operations, and should permit operations on separate portions of the list
to occur concurrently (so a single lock for the entire list will not sufﬁce).
(Hint: You will want to use a “walking lock” idiom in which acquire and
release operations are interleaved in non-LIFO order.)
13.15
(Difﬁcult) Implement a nonblocking version of the set of the previous ex-
ercise. (Hint: You will probably discover that insertion is easy but deletion
is hard. Consider a lazy deletion mechanism in which cleanup [physical re-
moval of a node] may occur well after logical completion of the removal.
For further details see the work of Harris [Har01].)
13.7 Exercises
693
13.16
To make spin locks useful on a multiprogrammed multiprocessor, one
might want to ensure that no process is ever preempted in the middle of a
critical section. That way it would always be safe to spin in user space, be-
cause the process holding the lock would be guaranteed to be running on
some other processor, rather than preempted and possibly in need of the
current processor. Explain why an operating system designer might not
want to give user processes the ability to disable preemption arbitrarily.
(Hint: Think about fairness and multiple users.) Can you suggest a way to
get around the problem? (References to several possible solutions can be
found in the paper by Kontothanassis, Wisniewski, and Scott [KWS97].)
13.17
Show how to use semaphores to construct a scheduler-based n-thread bar-
rier.
13.18
Prove that monitors and semaphores are equally powerful. That is, use
each to implement the other. In the monitor-based implementation of
semaphores, what is your monitor invariant?
13.19
Show how to use binary semaphores to implement general semaphores.
13.20
In Example 13.38 (Figure 13.15), suppose we replaced the middle four
lines of procedure P with
if S.N = 0
sleep on(S.Q)
S.N −:= 1
and the middle four lines of procedure V with
S.N +:= 1
if S.Q is nonempty
enqueue(ready list, dequeue(S.Q))
What is the problem with this new version? Explain how it connects to the
question of hints and absolutes in Section 13.4.1.
13.21
Suppose that every monitor has a separate mutual exclusion lock, so that
different threads can run in different monitors concurrently, and that we
want to release exclusion on both inner and outer monitors when a thread
waits in a nested call. When the thread awakens it will need to reacquire
the outer locks. How can we ensure its ability to do so? (Hint: Think
about the order in which to acquire locks, and be prepared to abandon
Hoare semantics. For further hints, see Wettstein [Wet78].)
13.22
Show how general semaphores can be implemented with conditional criti-
cal regions in which all threads wait for the same condition, thereby avoid-
ing the overhead of unproductive wake-ups.
13.23
Write code for a bounded buffer using the protected object mechanism of
Ada 95.
694
Chapter 13 Concurrency


![Figure 13.20 The Dining...](images/page_727_caption_Figure%2013.20%20The%20Dining%20Philosophers.%20Hungry%20philosophers%20must%20contend%20for%20the%20forks%20to%20their%20left%20a.png)
*Figure 13.20 The Dining Philosophers. Hungry philosophers must contend for the forks to their left and right in order to eat.*

13.24
Repeat the previous exercise in Java using synchronized statements or
methods. Try to make your solution as simple and conceptually clear as
possible. You will probably want to use notifyAll.
13.25
Give a more efﬁcient solution to the previous exercise that avoids the use of
notifyAll. (Warning: It is tempting to observe that the buffer can never
be both full and empty at the same time, and to assume therefore that
waiting threads are either all producers or all consumers. This need not
be the case, however: if the buffer ever becomes even a temporary perfor-
mance bottleneck, there may be an arbitrary number of waiting threads,
including both producers and consumers.)
13.26
Repeat the previous exercise using Java Lock variables.
13.27
Explain how escape analysis, mentioned brieﬂy in Sidebar 10.3, could be
used to reduce the cost of certain synchronized statements and methods
in Java.
13.28
The dining philosophers problem [Dij72] is a classic exercise in synchro-
nization (Figure 13.20). Five philosophers sit around a circular table. In
the center is a large communal plate of spaghetti. Each philosopher repeat-
edly thinks for a while and then eats for a while, at intervals of his or her
own choosing. On the table between each pair of adjacent philosophers is
a single fork. To eat, a philosopher requires both adjacent forks: the one
on the left and the one on the right. Because they share a fork, adjacent
philosophers cannot eat simultaneously.
Write a solution to the dining philosophers problem in which each
philosopher is represented by a process and the forks are represented by
shared data. Synchronize access to the forks using semaphores, monitors,
or conditional critical regions. Try to maximize concurrency.
