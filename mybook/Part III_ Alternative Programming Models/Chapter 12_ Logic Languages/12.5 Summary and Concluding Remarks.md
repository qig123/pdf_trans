# 12.5 Summary and Concluding Remarks

A complete characterization of the values of X for which ¬takes(X, his201) is true would require a complete exploration of the resolution tree, something that Prolog does only when all goals fail, or when repeatedly prompted with semi- colons. Mechanisms to incorporate some sort of “constructive negation” into logic programming are an active topic of research. ■ It is worth noting that the deﬁnition of \+ in terms of failure means that vari- EXAMPLE 12.38

Negation and instantiation able bindings are lost whenever \+ succeeds. For example:

?- takes(X, his201). X = jane_doe ?- \+(takes(X, his201)). false. ?- \+(\+(takes(X, his201))). true. % no value for X provided

When takes ﬁrst succeeds, X is bound to jane_doe. When the inner \+ fails, the binding is broken. Then when the outer \+ succeeds, a new binding is created to an uninstantiated value. Prolog provides no way to pull the binding of X out through the double negation. ■

3CHECK YOUR UNDERSTANDING 9. Explain the purpose of the cut (!) in Prolog. How does it relate to \+?

10. Describe three ways in which Prolog programs can depart from a pure logic programming model.

11. Describe the generate-and-test programming idiom. 12. Summarize Prolog’s facilities for database manipulation. Be sure to mention assert, retract, and clause. 13. What sorts of logical statements cannot be captured in Horn clauses?

14. What is the closed world assumption? What problems does it cause for logic programming?

12.5 Summary and Concluding Remarks

In this chapter we have focused on the logic model of computing. Where an imperative program computes principally through iteration and side effects, and a functional program computes principally through substitution of parameters into functions, a logic program computes through the resolution of logical state- ments, driven by the ability to unify variables and terms. Much of our discussion was driven by an examination of the principal logic language, Prolog, which we used to illustrate clauses and terms, resolution and

uniﬁcation, search/execution order, list manipulation, and high-order predicates for inspection and modiﬁcation of the logic database. Like imperative and functional programming, logic programming is related to constructive proofs. But where an imperative or functional program in some sense is a proof (of the ability to generate outputs from inputs), a logic program is a set of axioms from which the computer attempts to construct a proof. And where imperative and functional programming provide the full power of Turing machines and lambda calculus, respectively (ignoring hardware-imposed limits on arithmetic precision, disk and memory space, etc.), Prolog provides less than the full generality of resolution theorem proving, in the interests of time and space efﬁciency. At the same time, Prolog extends its formal counterpart with true arithmetic, I/O, imperative control ﬂow, and higher-order predicates for self- inspection and modiﬁcation. Like Lisp/Scheme, Prolog makes heavy use of lists, largely because they can easily be built incrementally, without the need to allocate and then modify state as separate operations. And like Lisp/Scheme (but unlike ML and its descendants), Prolog is homoiconic: programs look like ordinary data structures, and can be created, modiﬁed, and executed on the ﬂy. As we stressed in Chapter 1, different models of computing are appealing in different ways. Imperative programs more closely mirror the underlying hard- ware, and can more easily be “tweaked” for high performance. Purely functional programs avoid the semantic complexity of side effects, and have proved partic- ularly handy for the manipulation of symbolic (nonnumeric) data. Logic pro- grams, with their highly declarative semantics and their emphasis on uniﬁcation, are well suited to problems that emphasize relationships and search. At the same time, their de-emphasis of control ﬂow can lead to inefﬁciency. At the current state of the art, computers have surpassed people in their ability to deal with low- level details (e.g., of instruction scheduling), but people are still better at inventing good algorithms. As we also stressed in Chapter 1, the borders between language classes are often very fuzzy. The backtracking search of Prolog strongly resembles the execution of generators in Icon. Uniﬁcation in Prolog resembles (but is more powerful than) the pattern-matching capabilities of ML and Haskell. (Uniﬁcation is also used for type checking in ML and Haskell, and for template instantiation in C++, but those are compile-time activities.) There is much to be said for programming in a purely functional or logic-based style. While most Scheme and Prolog programs make some use of imperative language features, those features tend to be responsible for a disproportionate share of program bugs. At the same time, there seem to be programming tasks— interactive I/O, for example—that are almost impossible to accomplish without side effects.

